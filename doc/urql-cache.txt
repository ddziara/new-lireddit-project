[Normalized Caching]

[Normalizing Relational Data]

{
  __typename
  todo(id: 1) {
    __typename
    id
    title
    author {
      __typename
      id
      name
    }
  }
}
{
  "__typename": "Query",
  "todo": {
    "__typename": "Todo",
    "id": 1,
    "title": "implement graphcache",
    "author": {
      "__typename": "Author",
      "id": 1,
      "name": "urql-team"
    }
  }
}

* It must be able to walk the query document and JSON data of the result and cache the data, 
  normalizing it in the process and storing it in relational tables.

  query-doc           ---walk--->   ---normalize--->   ---store--->   relational-tables        
  json-data-result    ---walk--->   ---normalize--->   ---store--->  

* I must later be able to walk the query document and recreate the JSON data just
  by reading data from its cache, by reading entries from its in-memory relational tables.

  query-doc           ---walk--->       ---recreate--->  json-data
  relational-tables   ---reading--->    ---recreate--->   


The normalized cache can walk the query document. Each field that has no selection set
must be a "record", a field that can only be set to a scalar

  {
    some-field
  }

Each field that does have a selection set must be another "entity" or a list of "entities".

  {
    some-field {
        ...
    }
  }

The latter fields with selection sets are our relations between entities, like foreign key
in relational database. Furthermore, the normalized cache then can read __typename field
on ralated entities.

From the above document we can assume the following relations

  * Query.todo(id: 1) -> Todo
  * Todo.author -> author

However, this isn't quite enough yet to store relations from GraphQL results.
The normalized cache must also generate primary keys for each entity so that
it can store them in table-like data structures.
urql's Graphcache and Apollo assume that there may be an id or_id field in a given selection
set. With this logic the normalized cache will actually create "links" between
its relational data:

  * "Query", .todo(id: 1) -> "Todo:1"
  * "Todo:1", .author -> "Author:1"

As we can see, the query root type itself has a constant key of "Query". All relational data
oroginates here, since the GraphQL schema is a graph and, like a tree, all selections
on GraphQL query document oroginate from it. Internally, the normalized cache now stores field 
values on entities by their primary keys. The above can alsoe be said or written as:

  * The Query entity's todo field with ["id": 1] arguments points to the Todo:1 entity.
  * The Todo:1 entitie's author field points to the Authors:1 entity.

In Graphcache, these "links" are stored in the nested structure per-entity. "Records" are
kept separate from this relational data.

-------------------------
|  {                    |
|      --------------   | 
|      | __typename |   | <-------- Type Info    
|      --------------   |
|      ------  -------  |
|      | id |  | _id |  | <-------- Keys 
|      ------  -------  |           (either id, _id or custom)
|      ..........       |
|      : record :       | <-------- Fields
|      ..........       |
|      ..............   |
|      : link { o } :   |            Relations
|      .........|....   |         -----
|      ...      --------|---------| o |
|  }                    |         ----- 
-------------------------

[Storing Normalized Data]

We store all values of fields in a dictionary of their primary key, generated from an ID or other key
and type name, and the field's name and arguments, if it has any.

  Primary Key                         Field                         Value              

  Type name and ID (Key)              Field name (not alias)        Scalar value or
                                      and optionally arguments      relational

In Graphcache the data structure for these tables looks a little like the following, 
where each entity has a record from fields to other entity keys:

{
  links: Map {
    'Query': Record {
      'todo({"id":1})': 'Todo:1'
    },
    'Todo:1': Record {
      'author': 'Author:1'
    },
    'Author:1': Record { },
  }
}

{
  records: Map {
    'Query': Record {
      '__typename': 'Query'
    },
    'Todo:1': Record {
      '__typename': 'Todo',
      'id': 1,
      'title': 'implement graphcache'
    },
    'Author:1': Record {
      '__typename': 'Author',
      'id': 1,
      'name': 'urql-team'
    },
  }
}

Similarly queries may share data between one another which means that they effectively share entities 
using this approach and can update one another. In other words, once we have a primary key like 
"Todo:1" we may find this primary key again in other entities in other GraphQL results.

[Custom Keys and Non-Keyable Entities]

  {
    item {
      uuid
    }
  }

In the above selection set we have an item field that has a uuid field rather than an id field. 
This means that Graphcache won't automatically be able to generate a primary key for this entity. 
Instead, we have to help it generate a key by passing it a custom keys config:

  cacheExchange({
    keys: {
      Item: data => data.uuid,
    },
  });

 We may add a function as an entry to the keys configuration. The property here, "Item" must be 
 the typename of the entity for which we're generating a key. The function may return an arbitarily 
 generated key. So for our item field, which in our example schema gives us an Item entity, 
 we can create a keys configuration entry that creates a key from the uuid field rather than the id field.

This also raises a question, what does Graphcache do with unkeyable data by default? And, what if my data 
has no key?

This special case is what we call "embedded data". Not all types in a GraphQL schema will have keyable 
fields and some types may just abstract data without themselves being relational. They may be "edges", 
entities that have a field pointing to other entities that simply connect two entities, or data types 
like a GeoJson or Image type.

In these cases, where the normalized cache encounters unkeyable types, it will create an embedded key 
by using the parent's primary key and combining it with the field key. This means that "embedded entities" 
are only reachable from a specific field on their parent entities. They're globally unique and aren't 
strictly speaking relational data.

  {
    __typename
    todo(id: 1) {
      id
      image {
        url
        width
        height
      }
    }
  }

In the above example we're querying an Image type on a Todo. This imaginary Image type has no key because 
the image is embedded data and will only ever be associated to this Todo. In other words, the API's schema 
doesn't consider it necessary to have a primary key field for this type. Maybe it doesn't even have an ID 
in our backend's database. We could assign this type an imaginary key (maybe based on the url) but in fact 
if it's not shared data it wouldn't make much sense to do so. 

When Graphcache attempts to store this entity it will issue the previously mentioned warning. 
Internally, it'll then generate an embedded key for this entity based on the parent entity. If the parent 
entity's key is Todo:1 then the embedded key for our Image will become Todo:1.image. This is also how this 
entity will be stored internally by Graphcache:

  {
    records: Map {
      'Todo:1.image': Record {
        '__typename': 'Image',
        'url': '...',
        'width': 1024,
        'height': 768
      },
    }
  }

This doesn't however mute the warning that Graphcache outputs, since it believes we may have made a mistake. 
The warning itself gives us advice on how to mute it:

  If this is intentional, create a keys config for Image that always returns null. 

  cacheExchange({
    keys: {
      Image: () => null,
    },
  });

[Flexible Key Generation]

  cacheExchange({
    keys: new Proxy(
      {
        Image: () => null,
      },
      {
        get(target, prop, receiver) {
          if (prop.endsWith('Node')) {
            return data => data.uid;
          }
          const fallback = data => data.uuid;
          return target[prop] || fallback;
        },
      }
    ),
  });

[Non-Automatic Relations and Updates]

While Graphcache is able to store and update our entities in an in-memory relational data structure, 
which keeps the same entities in singular unique locations, a GraphQL API may make a lot of implicit 
changes to the relations of data as it runs or have trivial relations that our cache doesn't need 
to see to resolve. Like with the keys config, we have two more configuration options to combat this: 
resolvers and updates.

[Manually resolving entities]

Some fields in our configuration can be resolved without checking the GraphQL API for relations. 
The resolvers config allows us to create a list of client-side resolvers where we can read from 
the cache directly as Graphcache creates a local GraphQL result from its cached data.

  {
    todo(id: 1) {
      id
    }
  }

However, it may be possible for another query to have already written this Todo entity to the cache. 
So, how do we resolve a relation manually? 

In such a case, Graphcache may have seen and stored the Todo entity but isn't aware of the relation 
between Query.todo({"id":1}) and the Todo:1 entity. However, we can tell Graphcache which entity 
it should look for when it accesses the Query.todo field by creating a resolver for it:

  cacheExchange({
    resolvers: {
      Query: {
        todo(parent, args, cache, info) {
          return { __typename: 'Todo', id: args.id };
        },
      },
    },
  });

This mechanism is immensely more powerful than this example. We have two other use-cases that resolvers may be used for:

  * Resolvers can be applied to fields with records, which means that it can be used to change or transform scalar values. 
    For instance, we can update a string or parse a Date right inside a resolver.
  * Resolvers can return deeply nested results, which will be layered on top of the in-memory relational cached data 
    of Graphcache, which means that it can emulate infinite pagination and other complex behaviour.

[Manual cache updates]

While resolvers, as shown above, operate while Graphcache is reading from its in-memory cache, updates are 
a configuration option that operate while Graphcache is writing to its cached data. Specifically, 
these functions can be used to add more updates onto what a Mutation or Subscription may automatically update.

  query TodosList {
    todos {
      id
      title
    }
  }

  mutation AddTodo($title: String!) {
    addTodo(title: $title) {
      id
      title
    }
  }

In a simple example, like the one above, we have a list of todos in a query and create a new todo using 
the Mutation.addTodo mutation field. When the mutation is executed and we get the result back, 
Graphcache already writes the Todo item to its normalized cache. However, we also want to add the new Todo 
item to the list on Query.todos:  

  import { gql } from '@urql/core';

  cacheExchange({
    updates: {
      Mutation: {
        addTodo(result, args, cache, info) {
          const query = gql`
            {
              todos {
                id
              }
            }
          `;
          cache.updateQuery({ query }, data => {
            data.todos.push(result.addTodo);
            return data;
          });
        },
      },
    },
  });

We get methods like cache.updateQuery, cache.writeFragment, and cache.link in our 
updater functions, which aren't available to us in local resolvers, 
and can only be used in these updates entries to change the data that the cache holds.  

[Deterministic Cache Updates]

In terms of the "Manual Cache Updates" that we've talked about above and Optimistic Updates 
the limitations are pretty simple at first and if we use Graphcache as usual we may not even 
notice them:

  * When we make an optimistic change, we define what a mutation's result may look like once 
    the API responds in the future and apply this temporary result immediately. We store this 
    temporary data in a separate "layer". Once the real result comes back this layer can be 
    deleted and the real API result can be applied as usual.
  * When multiple optimistic updates are made at the same time, we never allow these layers 
    to be deleted separately. Instead Graphcache waits for all mutations to complete before 
    deleting the optimistic layers and applying the real API result. This means that 
    a mutation update cannot accidentally commit optimistic data to the cache permanently.
  * While an optimistic update has been applied, Graphcache stops refetching any queries 
    that contain this optimistic data so that it doesn't "flip back" to its non-optimistic 
    state without the optimistic update being applied. Otherwise we'd see a "flicker" in the UI.

These three principles are the basic mechanisms we can expect from Graphcache. The summary is: 
Graphcache groups optimistic mutations and pauses queries so that optimistic updates look 
as expected, which is an implementation detail we can mostly ignore when using it.

However, one implementation detail we cannot ignore is the last mechanism in Graphcache which 
is called "Commutativity". As we can tell, "optimistic updates" need to store their normalized 
results on a separate layer. This means that the previous data structure we've seen in Graphcache 
is actually more like a list, with many tables of links and entities.    

Each layer may contain optimistic results and have an order of preference. However, this order 
also applies to queries. Since queries are run in one order but their API results can come back 
to us in a very different order, if we access enough pages in a random order things can sometimes 
look rather weird. We may see that in an application on a slow network connection the results 
may vary depending on when their results came back.

                                   o
                                   |                                 
                           ...............
                 ----------: cache query :------------
                 |         ...............           |
                 |                 |                 | 
             ----|-----------------|-----------------V---
             |   |                 |                 O  |
             ----|-----------------|---------------------
             ....|.................|.....................
             :   |                 |                    :
             ....|.................|.....................
             ----V-----------------V---------------------
             |   O                 O                 O  |
             -------------------------------------------- 

          Commutativity means that we store data in separate layers.

Instead, Graphcache actually uses layers for any API result it receives. In case, an API result 
arrives out-of-order, it sorts them by precedence â€” or rather by when they've been requested. 
Overall, we don't have to worry about this, but Graphcache has mechanisms that keep our updates safe.          

